{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating GVI Predictions from GSV Images: Comprehensive Workflow**\n",
        "\n",
        "This colab illustrates the methodology to generate GSV images from a set of points and generate GVI predictions for them. We use the latitude and longitude of each point to query the Google Static API using custom parameters, and then feed the images into the Treepedia 2.0 ResNet model after appropriately resizing the images. The model outputs predictions that are saved to a CSV file by neighborhood for further analysis and visualization.\n",
        "\n",
        "We encourage you to follow along to generate your own predictions!\n"
      ],
      "metadata": {
        "id": "XEXF0WI-Bd1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Mount Your Drive and Create the Correct Folders\n",
        "\n",
        "First, create a main folder in your google drive for your project and save the sampled points in a file titled \"[Neighborhood Name]_Coords.csv\" within this folder. Additionally, [download](https://drive.google.com/open?id=1A9IoXdKYolJ3G8TdTrYaqHlh3rKZ5wo8) and save the \"weights_test.hdf5\" file and save it in this folder. If the hyperlink does not work the link to download the weights file can also be found in the [Treepedia 2.0 repository README file](https://github.com/billcai/treepedia_dl_public?tab=readme-ov-file).\n",
        "\n",
        "Now, navigate into the main folder you created.\n"
      ],
      "metadata": {
        "id": "VjK8ZrSsDG8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "JZlW_QY7r7Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd [MAIN_FOLDER_PATH]"
      ],
      "metadata": {
        "id": "D5Es02qgX2bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install Necessary Packages"
      ],
      "metadata": {
        "id": "6aEaamWTD4WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import model_lib as treepedia_dl\n",
        "from os import readlink\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LCMws-Nlsd_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Query the GSV API for Images\n",
        "\n",
        "Use the function below to query the GSV API for images. You must provide your Google API Key. For the code to work as expected, use image size \"400x400\".\n",
        "\n",
        "In our work, we choose to use the following values (for a more comprehensive list see the [Google Streeview Static API](https://developers.google.com/maps/documentation/streetview/request-streetview) page):\n",
        "\n",
        "*   **Camera Heading:** Set to 0 degrees to standardize image\n",
        "orientation and minimize directional bias\n",
        "*   **Pitch:** Set to 0 degrees to ensure the camera\n",
        "was directed straight ahead, parallel to the ground,\n",
        "allowing us to capture the landscapeâ€™s greenery without introducing vertical distortions\n",
        "* **Field of View:** Set to 90 degrees to provide a wide perspective of each\n",
        "streetscape while maintaining proportions\n",
        "\n"
      ],
      "metadata": {
        "id": "eQU942kREFbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible neighborhood names: Canton, Midtown, Roland_Park, Southwest_Baltimore\n",
        "# pass in false for fetch_images first to make sure that all coordinates work\n",
        "def readInNeighborhoodImages(neighborhood_name, api_key, size, heading, pitch, fov, fetch_images):\n",
        "  coords_df = pd.read_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name} Coords.csv').round(6)\n",
        "  img_paths = []\n",
        "  num_not_available = 0\n",
        "  for index, row in tqdm(coords_df.iterrows(), total=coords_df.shape[0]):\n",
        "      latitude = row['y']  # Adjust column name as necessary\n",
        "      longitude = row['x']  # Adjust column name as necessary\n",
        "\n",
        "      # Metadata URL\n",
        "      metadata_url = f\"https://maps.googleapis.com/maps/api/streetview/metadata?size={size}&location={latitude},{longitude}&heading={heading}&pitch={pitch}&fov={fov}&key={api_key}\"\n",
        "\n",
        "      # Send request for metadata\n",
        "      metadata_response = requests.get(metadata_url)\n",
        "      metadata = metadata_response.json()\n",
        "\n",
        "      if metadata['status'] == 'OK':\n",
        "          # Construct URL to access the image\n",
        "          img_paths.append(f'[MAIN_FOLDER_PATH]/{neighborhood_name}_{latitude}_{longitude}.jpg')\n",
        "          image_url = f\"https://maps.googleapis.com/maps/api/streetview?size={size}&location={latitude},{longitude}&heading={heading}&pitch={pitch}&fov={fov}&key={api_key}\"\n",
        "\n",
        "          # # Fetch and save the image\n",
        "          if (fetch_images):\n",
        "            image_response = requests.get(image_url)\n",
        "            if image_response.status_code == 200:\n",
        "                img = Image.open(BytesIO(image_response.content))\n",
        "                img.save(f'[MAIN_FOLDER_PATH]/{neighborhood_name}_{latitude}_{longitude}.jpg')\n",
        "      else:\n",
        "          num_not_available += 1\n",
        "          print(f\"No imagery available for location: {latitude}, {longitude} - Status: {metadata['status']}\")\n",
        "  print('total not available', num_not_available)\n",
        "  paths_df = pd.DataFrame(img_paths, columns=['ImagePath'])\n",
        "  paths_df.to_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name}ImgPaths.csv',  index=False)"
      ],
      "metadata": {
        "id": "t0T8O3xvOQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generating Predictions for Neighborhood Images\n",
        "\n",
        "Now that you have gathered your GSV images, we will will walk through how to use a pre-trained Treepedia model to generate predictions for images of a neighborhood. We will load the model, resize the images, and combine the predictions with their corresponding coordinates. The steps are described in detail below for your understanding. To execute them, just call the `generatePredictions` function defined below!\n",
        "\n",
        "**Step 1:** Load the Model\n",
        "\n",
        "\n",
        "First, we need to load the pre-trained Treepedia model from a weights file `weights_test.hdf5`.\n",
        "\n",
        "\n",
        "```\n",
        "print(\"Loading model from weights_test.hdf5\")\n",
        "model = treepedia_dl.load_keras_mod(\"weights_test.hdf5\")\n",
        "```\n",
        "\n",
        "\n",
        "**Step 2:** Call Function from Above to Load and Resize Images\n",
        "\n",
        "Next, we will load the image paths from a CSV file `({neighborhood_name}ImgPaths.csv)`, resize the images to match the model's input size, and extract their coordinates from the filenames.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "current_model = (224, 224, 3)\n",
        "imgdata_array, coordinates = load_and_resize_from_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name}ImgPaths.csv', current_model)\n",
        "```\n",
        "\n",
        "**Step 3:** Generate Predictions\n",
        "\n",
        "Now, we will use the loaded model to generate predictions for the resized images.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "predictions = model.predict(x=imgdata_array, batch_size=1, verbose=1)\n",
        "```\n",
        "\n",
        "\n",
        "**Step 4:** Combine Predictions with Coordinates\n",
        "\n",
        "Finally, we will combine the predictions with their corresponding coordinates and save the results to a CSV file `({neighborhood_name}_Prediction.csv)`.\n",
        "\n",
        "\n",
        "```\n",
        "df_coordinates = pd.DataFrame(coordinates, columns=['Latitude', 'Longitude'])\n",
        "df = pd.DataFrame(predictions, columns=[f'{neighborhood_name} Predictions'])\n",
        "combined_df = pd.concat([df_coordinates, df], axis=1)\n",
        "combined_df.to_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name}_Prediction.csv', index=False)\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "txEIacCiGuxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to preprocess GSV Images; This function is called by generatePredictions\n",
        "def load_and_resize_from_csv(csv_loc, current_model):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_loc)\n",
        "    test_data = df.iloc[:, 0].tolist()  # Assuming image paths are in the first column\n",
        "\n",
        "    imgdata = []\n",
        "    coordinates = []\n",
        "\n",
        "    for path in test_data:\n",
        "        img = Image.open(path)\n",
        "        img_resized = img.resize(current_model[:2])  # Resize according to the first two elements of current_model\n",
        "        imgdata.append(img_resized)\n",
        "        # Extract latitude and longitude from the filename\n",
        "        filename = path.split('/')[-1]  # Adjust the split based on your path format\n",
        "        parts = filename[:-4].split('_')  # Removes the file extension and splits at '_'\n",
        "        latitude, longitude = float(parts[-2]), float(parts[-1])\n",
        "        coordinates.append((latitude, longitude))\n",
        "\n",
        "    # Convert the list of PIL images to a numpy array with the appropriate shape\n",
        "    imgdata_array = np.zeros((len(imgdata), *current_model[:2], 3))  # Adjust the shape as necessary\n",
        "    for i, img in enumerate(imgdata):\n",
        "        imgdata_array[i] = np.array(img)\n",
        "\n",
        "    return imgdata_array, coordinates"
      ],
      "metadata": {
        "id": "qe72mbE1u7c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generatePredictions(neighborhood_name):\n",
        "  print(\"Loading model from weights_test.hdf5\")\n",
        "  model = treepedia_dl.load_keras_mod(\"weights_test.hdf5\")\n",
        "  current_model = (224, 224, 3)\n",
        "  imgdata_array, coordinates = load_and_resize_from_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name}ImgPaths.csv', current_model)\n",
        "  df_coordinates = pd.DataFrame(coordinates, columns=['Latitude', 'Longitude'])\n",
        "  print('Generating Predictions')\n",
        "  predictions = model.predict(x=imgdata_array,batch_size=1,verbose=1)\n",
        "\n",
        "  df = pd.DataFrame(predictions, columns=[f'{neighborhood_name} Predictions'])\n",
        "  combined_df = pd.concat([df_coordinates, df], axis=1)\n",
        "\n",
        "  combined_df.to_csv(f'[MAIN_FOLDER_PATH]/{neighborhood_name}_Prediction.csv', index=False)\n",
        "  return combined_df"
      ],
      "metadata": {
        "id": "GyOm2AdNVcH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate predictions and save the predictions to a csv just run the next cell after replacing the relevant variables."
      ],
      "metadata": {
        "id": "Kyt-vyRsvPFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generatePredictions('[Neighborhood_Name]').to_csv(f'[MAIN_FOLDER_PATH]/[Neighborhood_Name]_Prediction.csv', index=False)"
      ],
      "metadata": {
        "id": "llcrs1nLXUt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. You are Done!\n",
        "You have now successfully generated predictions for images of a neighborhood using the Treepedia 2.0 model. Feel free to explore the predictions and use them for further analysis or visualization!"
      ],
      "metadata": {
        "id": "2K4HRhTaH7jg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}